{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-16T14:20:48.481196Z","iopub.status.busy":"2023-11-16T14:20:48.480701Z","iopub.status.idle":"2023-11-16T14:20:56.624955Z","shell.execute_reply":"2023-11-16T14:20:56.624051Z","shell.execute_reply.started":"2023-11-16T14:20:48.481146Z"},"trusted":true},"outputs":[],"source":["\n","%matplotlib inline\n","import os\n","import cv2\n","import seaborn \n","import numpy as np\n","import pandas as pd \n","import random\n","import tqdm\n","from tqdm import notebook\n","import albumentations as A\n","from albumentations import pytorch\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as functional\n","import torchvision"]},{"cell_type":"markdown","metadata":{},"source":["# Define default paths"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T14:20:56.627390Z","iopub.status.busy":"2023-11-16T14:20:56.627099Z","iopub.status.idle":"2023-11-16T14:20:56.633501Z","shell.execute_reply":"2023-11-16T14:20:56.632615Z","shell.execute_reply.started":"2023-11-16T14:20:56.627350Z"},"trusted":true},"outputs":[],"source":["images_dir = '/kaggle/input/cityscapes-image-pairs/cityscapes_data'\n","train_images_dir = os.path.join(images_dir, 'train')\n","val_images_dir = os.path.join(images_dir, 'val')\n","working_dir = '/kaggle/working'\n","weights_path = os.path.join(working_dir, 'unet4_weights.pth')\n","logs_path = os.path.join(working_dir, 'logs')"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Generator Compatible with Torch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T14:20:56.634973Z","iopub.status.busy":"2023-11-16T14:20:56.634777Z","iopub.status.idle":"2023-11-16T14:20:56.654268Z","shell.execute_reply":"2023-11-16T14:20:56.653697Z","shell.execute_reply.started":"2023-11-16T14:20:56.634950Z"},"trusted":true},"outputs":[],"source":["class Generator(object):\n","    def __init__(self, images_dir, batch_size, is_augmentation, shuffle = True, rescale = 1.00, target_size = (128, 128)):\n","        super(Generator, self).__init__()\n","        self.images_dir = images_dir\n","        self.batch_size = batch_size\n","        self.rescale = rescale\n","        self.shuffle = shuffle\n","        self.is_augmentation = is_augmentation\n","        self.target_size = target_size\n","        self.filenames = [os.path.join(self.images_dir, filename) for filename in os.listdir(self.images_dir)]\n","        self.current_step = 0\n","        self.count_images = len(self.filenames)\n","        self.available_steps = int(self.count_images // self.batch_size)\n","        \n","        self.transforms = A.Compose([\n","            A.Rotate(25), \n","            A.OneOf([\n","                A.RGBShift(), A.HueSaturationValue()\n","            ]),\n","            A.OneOf([\n","                A.CLAHE(), A.RandomBrightnessContrast(), A.RandomGamma()\n","            ]), \n","        ])\n","    \n","    def augmentate(self, batch):\n","        batch = batch.astype(np.uint8)\n","        batch = [self.transforms(image = image, mask = mask) for (image, mask) in batch]\n","        batch = np.array([(transformed['image'], transformed['mask']) for transformed in batch], dtype = np.float32)\n","        return batch\n","            \n","    def generate_batch(self):\n","        start = self.current_step * self.batch_size\n","        stop = (self.current_step + 1) * self.batch_size\n","        filenames_batch = self.filenames[start:stop]\n","        \n","        images_batch = [cv2.imread(filename) for filename in filenames_batch]\n","        \n","        images_batch = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in images_batch])\n","        \n","        images_batch = np.array([(image[:, :256,], image[:, 256:]) for image in images_batch]) \n","        \n","        images_batch = np.array([(cv2.resize(image, self.target_size), cv2.resize(mask, self.target_size)) for (image, mask) in images_batch], dtype = np.float32)\n","        \n","        if self.is_augmentation:\n","            images_batch = self.augmentate(images_batch)\n","        \n","        images_batch = np.array([(np.moveaxis(image, -1, 0), np.moveaxis(mask, -1, 0)) for (image, mask) in images_batch])\n","        \n","        images_batch /= self.rescale\n","        images_batch = np.moveaxis(images_batch, 1, 0)\n","        \n","        return torch.Tensor(images_batch)\n","    \n","    def __next__(self):\n","        if self.current_step > self.available_steps:\n","            self.current_step = 0\n","        images, masks = self.generate_batch()\n","        self.current_step += 1\n","        return images, masks\n","    \n","    def __len__(self):\n","        return self.available_steps"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-11-16T14:20:56.655642Z","iopub.status.busy":"2023-11-16T14:20:56.655356Z","iopub.status.idle":"2023-11-16T14:20:58.493411Z","shell.execute_reply":"2023-11-16T14:20:58.492407Z","shell.execute_reply.started":"2023-11-16T14:20:56.655587Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["def show_examples(num_cols):\n","    stacks = []\n","    dataloader = Generator(images_dir = train_images_dir, batch_size = 8, is_augmentation = True, rescale = 255.0)\n","    for iteration in range(num_cols):\n","        images, masks = next(dataloader)\n","        images, masks = images.numpy(), masks.numpy()\n","        images, masks = np.concatenate(np.moveaxis(images, 1, -1)), np.concatenate(np.moveaxis(masks, 1, -1))\n","        embedded = (images + masks) / 2\n","        stack = np.hstack([images, masks, embedded])\n","        stacks.append(stack)\n","    result = np.hstack(stacks)\n","    plt.figure(figsize = (30, 30))\n","    plt.axis('off')\n","    plt.imshow(result)\n","show_examples(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T14:20:58.495837Z","iopub.status.busy":"2023-11-16T14:20:58.495574Z","iopub.status.idle":"2023-11-16T14:20:58.512076Z","shell.execute_reply":"2023-11-16T14:20:58.511141Z","shell.execute_reply.started":"2023-11-16T14:20:58.495808Z"},"trusted":true},"outputs":[],"source":["class DoubleConv(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.LeakyReLU(0.1),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.1)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Up(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = functional.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:21:32.287759Z","iopub.status.busy":"2023-11-16T15:21:32.287066Z","iopub.status.idle":"2023-11-16T15:21:32.304543Z","shell.execute_reply":"2023-11-16T15:21:32.303634Z","shell.execute_reply.started":"2023-11-16T15:21:32.287715Z"},"trusted":true},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=True):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        factor = 2 if bilinear else 1\n","        self.down4 = Down(512, 1024 // factor)\n","        self.up1 = Up(1024, 512 // factor, bilinear)\n","        self.up2 = Up(512, 256 // factor, bilinear)\n","        self.up3 = Up(256, 128 // factor, bilinear)\n","        self.up4 = Up(128, 64, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        logits = self.outc(x)\n","        return logits \n","    \n","    def mark_road(self, image_path):\n","        input_image = cv2.imread(image_path)\n","        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n","        input_image = cv2.resize(input_image, (128, 128))\n","        input_image = input_image / 255.0  \n","\n","\n","        input_image = transforms.ToTensor()(input_image)\n","        input_image = input_image.unsqueeze(0)\n","        with torch.no_grad():\n","            self.eval()\n","            output = self(input_image)\n","        output = torch.argmax(output, dim=1)\n","        road_mask = output.squeeze().cpu().numpy()\n","\n","        segmented_image = np.zeros_like(input_image.squeeze().numpy())\n","        segmented_image[road_mask == 1] = [1, 0, 0] \n","\n","        return segmented_image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:21:36.869477Z","iopub.status.busy":"2023-11-16T15:21:36.869186Z","iopub.status.idle":"2023-11-16T15:21:38.286567Z","shell.execute_reply":"2023-11-16T15:21:38.285948Z","shell.execute_reply.started":"2023-11-16T15:21:36.869445Z"},"trusted":true},"outputs":[],"source":["unet = UNet(n_channels=3, n_classes=3, bilinear=True)\n","x = torch.zeros(8, 3, 128, 128, dtype=torch.float, requires_grad=False)\n","out = unet(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:21:42.591734Z","iopub.status.busy":"2023-11-16T15:21:42.590995Z","iopub.status.idle":"2023-11-16T15:35:45.145235Z","shell.execute_reply":"2023-11-16T15:35:45.144361Z","shell.execute_reply.started":"2023-11-16T15:21:42.591689Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(params = unet.parameters(), \n","                             lr=1e-4, \n","                             betas=(0.9, 0.999), \n","                             eps=1e-08, \n","                             weight_decay=0, \n","                             amsgrad=False)\n","\n","criterion = torch.nn.BCEWithLogitsLoss()\n","\n","history = dict(train_loss = [], \n","               train_dice_coeff = [], \n","               test_loss = [], \n","               test_dice_coeff = [])\n","\n","def dice_coeff(pred, target):\n","    pred = (pred > 0).float()\n","    return 2. * (pred*target).sum() / (pred+target).sum()\n","            \n","def training(model, epochs, batch_size):\n"," \n","    train_generator = Generator(images_dir = train_images_dir, batch_size = batch_size, is_augmentation = True, rescale = 255.0)\n","    test_generator = Generator(images_dir = val_images_dir, batch_size = batch_size, is_augmentation = False, rescale = 255.0)\n","    \n","    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    \n","    main_pbar = tqdm.notebook.tqdm(range(epochs))\n","    main_pbar.set_description('common progress ')\n","    \n","    for epoch in main_pbar:\n","        running_params = dict(train_loss = [], \n","                               train_dice_coeff = [], \n","                               test_loss = [], \n","                               test_dice_coeff = [])\n","        train_pbar = tqdm.notebook.tqdm(range(len(train_generator)))\n","        \n","        for step in train_pbar:\n","            \n","            train_images, train_masks = next(train_generator)\n","            train_images, train_masks = train_images.to(device), train_masks.to(device)\n","            \n","            optimizer.zero_grad()\n","            \n","            train_predictions = model(train_images)\n","            train_loss = criterion(train_predictions, train_masks)\n","            train_loss.backward()\n","            \n","            train_dice_coeff = dice_coeff(pred = train_predictions, target = train_masks)\n","            \n","            optimizer.step()\n","        \n","        \n","       \n","            with torch.no_grad():\n","                test_images, test_masks = next(test_generator)\n","                test_images, test_masks = test_images.to(device), test_masks.to(device)\n","                test_predictions = model(test_images)\n","                test_loss = criterion(test_predictions, test_masks)\n","                test_dice_coeff = dice_coeff(pred = test_predictions, target = test_masks)\n","                \n","            \n","            current_metrics = dict(train_loss = [train_loss.item(), ], \n","                                   train_dice_coeff = [train_dice_coeff.item(), ], \n","                                   test_loss = [test_loss.item(),], \n","                                   test_dice_coeff = [test_dice_coeff.item(),])\n","            \n","            running_params.update(current_metrics)\n","            mean_metrics = dict(zip(running_params.keys(), [(sum(tensor) / (step + 1)) for tensor in running_params.values()]))\n","            train_pbar.set_postfix(mean_metrics)\n","            torch.cuda.empty_cache()\n","        \n","        history.update(running_params)\n","        best_loss = max(history['test_loss'])\n","        best_loss_index = history['test_loss'].index(best_loss)\n","        current_loss_index = history['test_loss'].index(test_loss.item())\n","        if abs(current_loss_index - best_loss_index) >= 5:\n","            for param_group in optim.param_groups:\n","                if param_group['lr'] * 0.1 > 1e-6:\n","                    print('reduce learning rate to', {param_group['lr'] * 0.1})\n","                    param_group['lr'] *= 0.1\n","\n","training(model = unet, epochs = 17, batch_size = 32)\n","torch.save(unet.state_dict(), weights_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:35:45.147584Z","iopub.status.busy":"2023-11-16T15:35:45.146947Z","iopub.status.idle":"2023-11-16T15:35:45.340935Z","shell.execute_reply":"2023-11-16T15:35:45.340140Z","shell.execute_reply.started":"2023-11-16T15:35:45.147542Z"},"trusted":true},"outputs":[],"source":["model = UNet(n_channels=3, n_classes=3, bilinear=True)\n","model.load_state_dict(torch.load(weights_path))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:35:45.342417Z","iopub.status.busy":"2023-11-16T15:35:45.342130Z","iopub.status.idle":"2023-11-16T15:35:49.866925Z","shell.execute_reply":"2023-11-16T15:35:49.865472Z","shell.execute_reply.started":"2023-11-16T15:35:45.342379Z"},"trusted":true},"outputs":[],"source":["def show_final_results(num_cols):\n","    generator = Generator(images_dir = val_images_dir, \n","                           batch_size = 8, \n","                           is_augmentation = True, \n","                           rescale = 255.0)\n","    result = []\n","    for iteration in range(num_cols):\n","        images, masks = next(generator)\n","        prediction = torch.sigmoid(model(images))\n","        prediction = prediction.cpu().detach().numpy()\n","        prediction = np.moveaxis(prediction, 1, -1)\n","        masks = np.moveaxis(masks.numpy(), 1, -1)\n","        images = np.moveaxis(images.numpy(), 1, -1)\n","        prediction = np.concatenate(prediction)\n","        images = np.concatenate(images)\n","        masks = np.concatenate(masks)\n","        merged = np.add(images, prediction) / 2\n","        outputs = np.hstack([images, masks, prediction, merged])\n","        result.append(outputs)\n","    result = np.hstack(result)\n","    plt.figure(figsize = (30, 30))\n","    plt.axis('off')\n","    plt.imshow(result)\n","\n","show_final_results(num_cols = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-16T15:35:49.868761Z","iopub.status.busy":"2023-11-16T15:35:49.868510Z","iopub.status.idle":"2023-11-16T15:35:49.876825Z","shell.execute_reply":"2023-11-16T15:35:49.876056Z","shell.execute_reply.started":"2023-11-16T15:35:49.868733Z"},"trusted":true},"outputs":[],"source":["model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])\n","print(f'model parameters: {params}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), model_path)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":22655,"sourceId":29047,"sourceType":"datasetVersion"},{"datasetId":1585152,"sourceId":2607971,"sourceType":"datasetVersion"}],"dockerImageVersionId":30124,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
